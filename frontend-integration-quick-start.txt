FRONTEND INTEGRATION QUICK START GUIDE
=====================================

ðŸš€ READY-TO-USE API ENDPOINTS FOR EXTERNAL FRONTEND
===================================================

BASE URL: https://ai-mock-pitching-427457295403.europe-west1.run.app/

ðŸ“‹ COMPLETE INTEGRATION FLOW
============================

1. PERSONA SELECTION
   GET /api/personas
   Returns: All available investor personas with details

2. WEBSOCKET CONNECTION
   Connect to: wss://ai-mock-pitching-427457295403.europe-west1.run.app/socket.io
   Events: text_message (send), response (receive)

3. REAL-TIME CHAT
   Send: text_message with {text, persona, session_id, system}
   Send: audio_chunk with {audio_data, session_id, persona, is_final}
   Receive: response with {message, audio_url, stage, complete}
   Receive: transcription with {text, is_final, session_id}

4. END SESSION & ANALYSIS
   POST /api/pitch/end/{session_id}
   GET /api/pitch/analysis/{session_id}

ðŸ”Œ QUICK SETUP COMMANDS
======================

# React Setup
npm install socket.io-client axios
# Import: import io from 'socket.io-client';

# Vue Setup  
npm install socket.io-client axios
# Import: import io from 'socket.io-client';

# Angular Setup
npm install socket.io-client axios
# Import: import io from 'socket.io-client';

ðŸ“¡ ESSENTIAL API CALLS
=====================

1. LOAD PERSONAS:
   fetch('https://ai-mock-pitching-427457295403.europe-west1.run.app/api/personas')
   .then(res => res.json())
   .then(data => console.log(data.personas))

2. CONNECT WEBSOCKET:
   const socket = io('https://ai-mock-pitching-427457295403.europe-west1.run.app/');
   socket.on('connect', () => console.log('Connected'));

3. SEND MESSAGE:
   socket.emit('text_message', {
     text: 'Hello, I am Alex from Vertex',
     persona: 'skeptical',
     session_id: 'session_' + Date.now(),
     system: 'workflow'
   });

4. RECEIVE RESPONSE:
   socket.on('response', (data) => {
     console.log('AI:', data.message);
     if (data.audio_url) {
       playAudio('https://ai-mock-pitching-427457295403.europe-west1.run.app' + data.audio_url);
     }
   });

5. END SESSION:
   fetch(`https://ai-mock-pitching-427457295403.europe-west1.run.app/api/pitch/end/${sessionId}`, {
     method: 'POST',
     headers: {'Content-Type': 'application/json'},
     body: JSON.stringify({reason: 'user_ended'})
   })

6. GET ANALYSIS:
   fetch(`https://ai-mock-pitching-427457295403.europe-west1.run.app/api/pitch/analysis/${sessionId}`)
   .then(res => res.json())
   .then(data => console.log(data.analysis))

ðŸ“Š NEW ANALYSIS STRUCTURE
=========================

The analysis now includes 10 key categories with detailed scoring:

1. HOOKS & STORY - Opening engagement and storytelling
2. PROBLEM & URGENCY - Problem identification and urgency
3. SOLUTION & FIT - Solution clarity and product-market fit
4. MARKET & OPPORTUNITY - Market size and opportunity assessment
5. TEAM & EXECUTION - Team strength and execution capability
6. BUSINESS MODEL - Revenue model and monetization strategy
7. COMPETITIVE EDGE - Differentiation and competitive advantage
8. TRACTION & VISION - Current progress and future roadmap
9. FUNDING ASK - Funding requirements and use of funds
10. CLOSING IMPACT - Call to action and memorable closing

Rating Scale:
- Need to Improve (0-39): Significant gaps, major work needed
- Below Average (40-59): Some elements present, needs improvement
- Satisfactory (60-74): Meets basic requirements, room for enhancement
- Good (75-89): Strong performance, minor improvements needed
- Vertx Assured (90-100): Exceptional, investor-ready quality

ðŸŽ¤ REAL-TIME AUDIO STREAMING
===========================

7. START AUDIO RECORDING:
   socket.emit('start_recording', {
     session_id: sessionId,
     persona: 'skeptical',
     sample_rate: 16000
   });

8. SEND AUDIO CHUNKS:
   // Convert audio to base64
   const audioBase64 = arrayBufferToBase64(audioBuffer);
   socket.emit('audio_chunk', {
     audio_data: audioBase64,
     session_id: sessionId,
     persona: 'skeptical',
     is_final: false
   });

9. RECEIVE TRANSCRIPTIONS:
   socket.on('transcription', (data) => {
     if (data.is_final) {
       console.log('Final:', data.text);
     } else {
       console.log('Interim:', data.text);
     }
   });

10. STOP RECORDING:
    socket.emit('stop_recording', { session_id: sessionId });

ðŸŽ¯ MINIMAL WORKING EXAMPLE (React)
=================================

import React, { useState, useEffect } from 'react';
import io from 'socket.io-client';

function PitchApp() {
  const [socket, setSocket] = useState(null);
  const [sessionId, setSessionId] = useState(null);
  const [message, setMessage] = useState('');
  const [responses, setResponses] = useState([]);
  const [isRecording, setIsRecording] = useState(false);
  const [transcription, setTranscription] = useState('');

  useEffect(() => {
    const newSocket = io('https://ai-mock-pitching-427457295403.europe-west1.run.app/');
    setSocket(newSocket);
    
    newSocket.on('response', (data) => {
      setResponses(prev => [...prev, data.message]);
      if (data.audio_url) {
        const audio = new Audio('https://ai-mock-pitching-427457295403.europe-west1.run.app' + data.audio_url);
        audio.play();
      }
    });

    newSocket.on('transcription', (data) => {
      if (data.is_final) {
        setTranscription('');
        // Final transcription will trigger AI response
      } else {
        setTranscription(data.text);
      }
    });

    return () => newSocket.close();
  }, []);

  const startSession = () => {
    setSessionId('session_' + Date.now());
  };

  const sendMessage = () => {
    if (socket && sessionId && message) {
      socket.emit('text_message', {
        text: message,
        persona: 'skeptical',
        session_id: sessionId,
        system: 'workflow'
      });
      setMessage('');
    }
  };

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mediaRecorder = new MediaRecorder(stream);
      
      socket.emit('start_recording', {
        session_id: sessionId,
        persona: 'skeptical',
        sample_rate: 16000
      });

      mediaRecorder.ondataavailable = async (event) => {
        if (event.data.size > 0) {
          const arrayBuffer = await event.data.arrayBuffer();
          const base64Audio = btoa(String.fromCharCode(...new Uint8Array(arrayBuffer)));
          
          socket.emit('audio_chunk', {
            audio_data: base64Audio,
            session_id: sessionId,
            persona: 'skeptical',
            is_final: false
          });
        }
      };

      mediaRecorder.start(100); // Send chunks every 100ms
      setIsRecording(true);
      
      // Stop after 5 seconds (or implement stop button)
      setTimeout(() => {
        mediaRecorder.stop();
        stream.getTracks().forEach(track => track.stop());
        socket.emit('stop_recording', { session_id: sessionId });
        setIsRecording(false);
      }, 5000);
      
    } catch (error) {
      console.error('Error accessing microphone:', error);
    }
  };

  return (
    <div>
      <button onClick={startSession}>Start Session</button>
      <input 
        value={message} 
        onChange={(e) => setMessage(e.target.value)}
        placeholder="Type your message"
        disabled={isRecording}
      />
      <button onClick={sendMessage} disabled={isRecording}>Send Text</button>
      <button onClick={startRecording} disabled={!sessionId || isRecording}>
        {isRecording ? 'ðŸŽ¤ Recording...' : 'ðŸŽ¤ Record Voice'}
      </button>
      
      {transcription && <p>Listening: {transcription}</p>}
      
      <div>
        {responses.map((resp, i) => <p key={i}>{resp}</p>)}
      </div>
    </div>
  );
}

export default PitchApp;

ðŸŽ¯ MINIMAL WORKING EXAMPLE (Vue)
===============================

<template>
  <div>
    <button @click="startSession">Start Session</button>
    <input v-model="message" placeholder="Type your message" :disabled="isRecording" />
    <button @click="sendMessage" :disabled="isRecording">Send Text</button>
    <button @click="startRecording" :disabled="!sessionId || isRecording">
      {{ isRecording ? 'ðŸŽ¤ Recording...' : 'ðŸŽ¤ Record Voice' }}
    </button>
    
    <p v-if="transcription">Listening: {{ transcription }}</p>
    
    <div>
      <p v-for="(resp, i) in responses" :key="i">{{ resp }}</p>
    </div>
  </div>
</template>

<script>
import io from 'socket.io-client';

export default {
  data() {
    return {
      socket: null,
      sessionId: null,
      message: '',
      responses: [],
      isRecording: false,
      transcription: ''
    };
  },
  
  mounted() {
    this.socket = io('https://ai-mock-pitching-427457295403.europe-west1.run.app/');
    
    this.socket.on('response', (data) => {
      this.responses.push(data.message);
      if (data.audio_url) {
        const audio = new Audio('https://ai-mock-pitching-427457295403.europe-west1.run.app' + data.audio_url);
        audio.play();
      }
    });

    this.socket.on('transcription', (data) => {
      if (data.is_final) {
        this.transcription = '';
      } else {
        this.transcription = data.text;
      }
    });
  },
  
  methods: {
    startSession() {
      this.sessionId = 'session_' + Date.now();
    },
    
    sendMessage() {
      if (this.socket && this.sessionId && this.message) {
        this.socket.emit('text_message', {
          text: this.message,
          persona: 'skeptical',
          session_id: this.sessionId,
          system: 'workflow'
        });
        this.message = '';
      }
    },

    async startRecording() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        const mediaRecorder = new MediaRecorder(stream);
        
        this.socket.emit('start_recording', {
          session_id: this.sessionId,
          persona: 'skeptical',
          sample_rate: 16000
        });

        mediaRecorder.ondataavailable = async (event) => {
          if (event.data.size > 0) {
            const arrayBuffer = await event.data.arrayBuffer();
            const base64Audio = btoa(String.fromCharCode(...new Uint8Array(arrayBuffer)));
            
            this.socket.emit('audio_chunk', {
              audio_data: base64Audio,
              session_id: this.sessionId,
              persona: 'skeptical',
              is_final: false
            });
          }
        };

        mediaRecorder.start(100);
        this.isRecording = true;
        
        setTimeout(() => {
          mediaRecorder.stop();
          stream.getTracks().forEach(track => track.stop());
          this.socket.emit('stop_recording', { session_id: this.sessionId });
          this.isRecording = false;
        }, 5000);
        
      } catch (error) {
        console.error('Error accessing microphone:', error);
      }
    }
  }
};
</script>

ðŸ“Š API RESPONSE FORMATS
======================

PERSONAS RESPONSE:
{
  "success": true,
  "personas": {
    "skeptical": {
      "name": "Sarah Martinez",
      "title": "Senior Partner at Venture Capital",
      "description": "Analytical and thorough investor...",
      "personality_traits": ["Detail-oriented", "Risk-averse"],
      "focus_areas": ["Market validation", "Financial projections"],
      "typical_questions": ["What's your customer acquisition cost?"]
    }
  },
  "total_count": 3,
  "available_personas": ["skeptical", "technical", "friendly"]
}

WEBSOCKET RESPONSE:
{
  "message": "Hello Alex! Nice to meet you. Can you give me a brief overview of what Vertex does?",
  "audio_url": "/download/session_123_response_456.mp3",
  "stage": "introduction",
  "complete": false,
  "insights": {},
  "type": "workflow"
}

TRANSCRIPTION RESPONSE:
{
  "text": "Hello, I am Alex from Vertex and we are building...",
  "is_final": true,
  "session_id": "session_123",
  "confidence": 0.95
}

ANALYSIS RESPONSE:
{
  "success": true,
  "analysis": {
    "overall_score": 75,
    "overall_rating": "Good",
    "overall_description": "Strong foundation with good engagement across most categories",
    "completion_percentage": 80,
    "pitch_readiness": "Ready",
    "session_duration_minutes": 15,
    "category_scores": {
      "hooks_story": {
        "score": 78,
        "rating": "Good",
        "description": "Engaging opening with compelling narrative"
      },
      "problem_urgency": {
        "score": 82,
        "rating": "Good", 
        "description": "Clear problem identification with urgency"
      },
      "solution_fit": {
        "score": 75,
        "rating": "Good",
        "description": "Solution clearly presented with good fit"
      },
      "market_opportunity": {
        "score": 68,
        "rating": "Satisfactory",
        "description": "Market size mentioned, needs more data"
      },
      "team_execution": {
        "score": 80,
        "rating": "Good",
        "description": "Strong team with relevant experience"
      },
      "business_model": {
        "score": 65,
        "rating": "Satisfactory",
        "description": "Revenue model needs clearer strategy"
      },
      "competitive_edge": {
        "score": 70,
        "rating": "Satisfactory",
        "description": "Needs stronger differentiation"
      },
      "traction_vision": {
        "score": 85,
        "rating": "Good",
        "description": "Good traction with clear vision"
      },
      "funding_ask": {
        "score": 60,
        "rating": "Satisfactory",
        "description": "Use of funds needs more detail"
      },
      "closing_impact": {
        "score": 72,
        "rating": "Satisfactory",
        "description": "Could be more impactful"
      }
    },
    "strengths": [
      {
        "area": "Problem Definition",
        "description": "Clear articulation of the problem",
        "score": 8
      }
    ],
    "weaknesses": [
      {
        "area": "Market Size",
        "description": "Need more specific market data",
        "improvement": "Include market research and validation"
      }
    ],
    "key_recommendations": [
      "Strengthen market opportunity with specific data",
      "Provide detailed funding allocation breakdown",
      "Enhance competitive differentiation"
    ],
    "investor_perspective": "Good potential with strong team, needs market validation",
    "next_steps": [
      "Conduct market research",
      "Prepare financial projections"
    ]
  }
}

ðŸ”§ TROUBLESHOOTING
=================

1. CONNECTION ISSUES:
   - Backend is hosted on Google Cloud Run (not localhost)
   - Verify CORS settings allow your frontend domain
   - Test WebSocket connection in browser dev tools
   - Use HTTPS URLs for production deployment

2. AUDIO NOT PLAYING:
   - Check browser audio permissions
   - Verify audio URL is accessible
   - Add cache busting: audio.src = url + '?t=' + Date.now()

3. NO RESPONSE FROM AI:
   - Check session_id is being sent correctly
   - Verify persona name is valid
   - Check backend logs for errors

4. API ERRORS:
   - Verify endpoint URLs are correct
   - Check request headers and body format
   - Handle HTTP status codes properly

5. AUDIO RECORDING ISSUES:
   - Check microphone permissions in browser
   - Verify getUserMedia() is supported
   - Test with HTTPS (required for microphone access)
   - Check audio format compatibility

6. TRANSCRIPTION NOT WORKING:
   - Verify WebSocket connection is active
   - Check audio chunk size and format
   - Ensure proper base64 encoding
   - Test with different browsers

ðŸš€ PRODUCTION CHECKLIST
======================

â–¡ Update API URLs for production environment
â–¡ Configure CORS for production domain
â–¡ Add error handling and loading states
â–¡ Implement audio controls (play/pause/volume)
â–¡ Add message history and pagination
â–¡ Set up proper state management
â–¡ Add unit and integration tests
â–¡ Configure environment variables
â–¡ Implement user authentication if needed
â–¡ Add analytics and monitoring

ðŸŽ¤ AUDIO-SPECIFIC CHECKLIST
==========================

â–¡ Test microphone permissions across browsers
â–¡ Implement audio recording indicators
â–¡ Add audio quality settings (sample rate, bitrate)
â–¡ Handle network interruptions during recording
â–¡ Add push-to-talk vs continuous recording options
â–¡ Implement audio level visualization
â–¡ Add noise cancellation settings
â–¡ Test with different audio devices
â–¡ Implement audio recording time limits
â–¡ Add offline audio caching

ðŸ“ž SUPPORT
=========

If you encounter issues:
1. Check browser console for errors
2. Verify backend server is running
3. Test API endpoints with Postman/curl
4. Check WebSocket connection status
5. Review network requests in dev tools

ðŸŽ¯ YOU'RE READY TO INTEGRATE!
============================

Your backend provides a complete API for:
âœ… Persona selection
âœ… Real-time WebSocket communication  
âœ… Audio response generation
âœ… Session management
âœ… Comprehensive pitch analysis

The API is production-ready and can be integrated with any modern frontend framework!